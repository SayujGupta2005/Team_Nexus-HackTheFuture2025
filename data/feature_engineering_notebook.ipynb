{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading ( ensure correct path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_hh = pd.read_csv('hh-level-train-data.csv') #Household level train data\n",
    "train_data_per = pd.read_csv('person-level-train-data.csv') #Individual level trian data\n",
    "train_data_hh_path = 'hh-level-train-data.csv'\n",
    "train_data_per_path = 'person-level-train-data.csv'\n",
    "test_data_hh = pd.read_csv('hh-level-test-data.csv') #Household level test data\n",
    "test_data_per = pd.read_csv('person-level-test-data.csv') #Individual level test data\n",
    "test_data_hh_path = 'hh-level-test-data.csv'    \n",
    "test_data_per_path = 'person-level-test-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HH_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sector",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "State",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NSS-Region",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "District",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Household Type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Religion of the head of the household",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Social Group of the head of the household",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HH Size (For FDQ)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NCO_3D",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NIC_5D",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Clothing_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Footwear_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Furniture_fixturesPurchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Mobile_Handset_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Personal_Goods_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Recreation_Goods_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Household_Appliances_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Crockery_Utensils_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Sports_Goods_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Medical_Equipment_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_online_Bedding_Purchased_Last365",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Television",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Radio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Laptop_PC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Mobile_handset",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Bicycle",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Motorcycle_scooter",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Motorcar_jeep_van",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Trucks",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Animal_cart",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Refrigerator",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Washing_machine",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Is_HH_Have_Airconditioner_aircooler",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TotalExpense",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1d7e3012-8324-4812-ab77-0f2bc12a75d5",
       "rows": [
        [
         "0",
         "HCES2022699591212130623068221111306",
         "1",
         "21",
         "213",
         "6",
         "6",
         "1",
         "1",
         "2",
         "931.0",
         "41001.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "4252.405088062622"
        ],
        [
         "1",
         "HCES2022325492191931132028219201301",
         "2",
         "19",
         "193",
         "11",
         "1",
         "1",
         "9",
         "1",
         "522.0",
         "56101.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "1.0",
         null,
         "1.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "4900.391389432486"
        ],
        [
         "2",
         "HCES2022331532151510322037115101308",
         "2",
         "15",
         "151",
         "3",
         "2",
         "3",
         "1",
         "5",
         "411.0",
         "84119.0",
         null,
         "1.0",
         null,
         "1.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "1.0",
         null,
         null,
         "1.0",
         null,
         "1.0",
         null,
         null,
         null,
         "1.0",
         "1.0",
         null,
         "34304.682974559684"
        ],
        [
         "3",
         "HCES2022622821121210923037212102315",
         "1",
         "12",
         "121",
         "9",
         "1",
         "6",
         "9",
         "6",
         "611.0",
         "1252.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "18091.95890410959"
        ],
        [
         "4",
         "HCES20223918022929318420110229101301",
         "2",
         "29",
         "293",
         "18",
         "9",
         "1",
         "3",
         "2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "1.0",
         null,
         null,
         "1.0",
         null,
         "1.0",
         null,
         null,
         null,
         "1.0",
         "1.0",
         null,
         "23454.68884540117"
        ]
       ],
       "shape": {
        "columns": 35,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH_ID</th>\n",
       "      <th>Sector</th>\n",
       "      <th>State</th>\n",
       "      <th>NSS-Region</th>\n",
       "      <th>District</th>\n",
       "      <th>Household Type</th>\n",
       "      <th>Religion of the head of the household</th>\n",
       "      <th>Social Group of the head of the household</th>\n",
       "      <th>HH Size (For FDQ)</th>\n",
       "      <th>NCO_3D</th>\n",
       "      <th>...</th>\n",
       "      <th>Is_HH_Have_Mobile_handset</th>\n",
       "      <th>Is_HH_Have_Bicycle</th>\n",
       "      <th>Is_HH_Have_Motorcycle_scooter</th>\n",
       "      <th>Is_HH_Have_Motorcar_jeep_van</th>\n",
       "      <th>Is_HH_Have_Trucks</th>\n",
       "      <th>Is_HH_Have_Animal_cart</th>\n",
       "      <th>Is_HH_Have_Refrigerator</th>\n",
       "      <th>Is_HH_Have_Washing_machine</th>\n",
       "      <th>Is_HH_Have_Airconditioner_aircooler</th>\n",
       "      <th>TotalExpense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HCES2022699591212130623068221111306</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>213</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>931.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4252.405088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCES2022325492191931132028219201301</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>193</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>522.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4900.391389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HCES2022331532151510322037115101308</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>411.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34304.682975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCES2022622821121210923037212102315</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>611.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18091.958904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCES20223918022929318420110229101301</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>293</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23454.688845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  HH_ID  Sector  State  NSS-Region  District  \\\n",
       "0   HCES2022699591212130623068221111306       1     21         213         6   \n",
       "1   HCES2022325492191931132028219201301       2     19         193        11   \n",
       "2   HCES2022331532151510322037115101308       2     15         151         3   \n",
       "3   HCES2022622821121210923037212102315       1     12         121         9   \n",
       "4  HCES20223918022929318420110229101301       2     29         293        18   \n",
       "\n",
       "   Household Type  Religion of the head of the household  \\\n",
       "0               6                                      1   \n",
       "1               1                                      1   \n",
       "2               2                                      3   \n",
       "3               1                                      6   \n",
       "4               9                                      1   \n",
       "\n",
       "   Social Group of the head of the household  HH Size (For FDQ)  NCO_3D  ...  \\\n",
       "0                                          1                  2   931.0  ...   \n",
       "1                                          9                  1   522.0  ...   \n",
       "2                                          1                  5   411.0  ...   \n",
       "3                                          9                  6   611.0  ...   \n",
       "4                                          3                  2     NaN  ...   \n",
       "\n",
       "   Is_HH_Have_Mobile_handset  Is_HH_Have_Bicycle  \\\n",
       "0                        1.0                 1.0   \n",
       "1                        1.0                 NaN   \n",
       "2                        1.0                 NaN   \n",
       "3                        1.0                 1.0   \n",
       "4                        1.0                 NaN   \n",
       "\n",
       "   Is_HH_Have_Motorcycle_scooter  Is_HH_Have_Motorcar_jeep_van  \\\n",
       "0                            NaN                           NaN   \n",
       "1                            NaN                           NaN   \n",
       "2                            1.0                           NaN   \n",
       "3                            NaN                           NaN   \n",
       "4                            1.0                           NaN   \n",
       "\n",
       "   Is_HH_Have_Trucks  Is_HH_Have_Animal_cart  Is_HH_Have_Refrigerator  \\\n",
       "0                NaN                     NaN                      NaN   \n",
       "1                NaN                     NaN                      NaN   \n",
       "2                NaN                     NaN                      1.0   \n",
       "3                NaN                     NaN                      NaN   \n",
       "4                NaN                     NaN                      1.0   \n",
       "\n",
       "   Is_HH_Have_Washing_machine  Is_HH_Have_Airconditioner_aircooler  \\\n",
       "0                         NaN                                  NaN   \n",
       "1                         NaN                                  NaN   \n",
       "2                         1.0                                  NaN   \n",
       "3                         NaN                                  NaN   \n",
       "4                         1.0                                  NaN   \n",
       "\n",
       "   TotalExpense  \n",
       "0   4252.405088  \n",
       "1   4900.391389  \n",
       "2  34304.682975  \n",
       "3  18091.958904  \n",
       "4  23454.688845  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_hh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for training of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  HH_ID  Sector  State  NSS-Region  District  \\\n",
      "0   HCES2022619881191951823044219131316       1     19         195        18   \n",
      "1   HCES2022617721191931723197219202205       1     19         193        17   \n",
      "2   HCES2022632771101011022015110131311       1     10         101        10   \n",
      "3   HCES2022357832080822112037108101306       2      8          82        21   \n",
      "4  HCES20226869012727230232010227422206       1     27         272        30   \n",
      "\n",
      "   Household Type  Religion of the head of the household  \\\n",
      "0               2                                      1   \n",
      "1               4                                      1   \n",
      "2               4                                      1   \n",
      "3               1                                      1   \n",
      "4               1                                      1   \n",
      "\n",
      "   Social Group of the head of the household  HH Size (For FDQ)  NCO_3D  ...  \\\n",
      "0                                          2                  2   731.0  ...   \n",
      "1                                          9                  4   325.0  ...   \n",
      "2                                          3                  3   512.0  ...   \n",
      "3                                          9                  4   611.0  ...   \n",
      "4                                          9                  3   611.0  ...   \n",
      "\n",
      "   Is_HH_Have_Mobile_handset  Is_HH_Have_Bicycle  \\\n",
      "0                        NaN                 1.0   \n",
      "1                        1.0                 1.0   \n",
      "2                        1.0                 NaN   \n",
      "3                        1.0                 NaN   \n",
      "4                        1.0                 NaN   \n",
      "\n",
      "   Is_HH_Have_Motorcycle_scooter  Is_HH_Have_Motorcar_jeep_van  \\\n",
      "0                            NaN                           NaN   \n",
      "1                            NaN                           NaN   \n",
      "2                            NaN                           NaN   \n",
      "3                            1.0                           NaN   \n",
      "4                            1.0                           NaN   \n",
      "\n",
      "   Is_HH_Have_Trucks  Is_HH_Have_Animal_cart  Is_HH_Have_Refrigerator  \\\n",
      "0                NaN                     NaN                      NaN   \n",
      "1                NaN                     NaN                      NaN   \n",
      "2                NaN                     NaN                      NaN   \n",
      "3                NaN                     NaN                      1.0   \n",
      "4                NaN                     NaN                      NaN   \n",
      "\n",
      "   Is_HH_Have_Washing_machine  Is_HH_Have_Airconditioner_aircooler  \\\n",
      "0                         NaN                                  NaN   \n",
      "1                         NaN                                  NaN   \n",
      "2                         NaN                                  NaN   \n",
      "3                         NaN                                  1.0   \n",
      "4                         NaN                                  1.0   \n",
      "\n",
      "   TotalExpense  \n",
      "0   2174.011742  \n",
      "1   3157.794521  \n",
      "2   3951.831050  \n",
      "3   6306.098337  \n",
      "4   4697.165036  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "                                  HH_ID  Sector  State  NSS-Region  District  \\\n",
      "0   HCES2022619881191951823044219131316       1     19         195        18   \n",
      "1   HCES2022617721191931723197219202205       1     19         193        17   \n",
      "2   HCES2022632771101011022015110131311       1     10         101        10   \n",
      "3   HCES2022357832080822112037108101306       2      8          82        21   \n",
      "4  HCES20226869012727230232010227422206       1     27         272        30   \n",
      "\n",
      "   Household Type  Religion of the head of the household  \\\n",
      "0               2                                      1   \n",
      "1               4                                      1   \n",
      "2               4                                      1   \n",
      "3               1                                      1   \n",
      "4               1                                      1   \n",
      "\n",
      "   Social Group of the head of the household  HH Size (For FDQ)  profession  \\\n",
      "0                                          2                  2         8.0   \n",
      "1                                          9                  4         4.0   \n",
      "2                                          3                  3         6.0   \n",
      "3                                          9                  4         7.0   \n",
      "4                                          9                  3         7.0   \n",
      "\n",
      "   ...  head_education_years  male_to_total_ratio  Is_couple  \\\n",
      "0  ...                     7             0.500000          2   \n",
      "1  ...                    13             0.500000          2   \n",
      "2  ...                    10             0.333333          0   \n",
      "3  ...                    18             0.250000          2   \n",
      "4  ...                     4             0.333333          0   \n",
      "\n",
      "   Highest educational level attained (code)  \\\n",
      "0                                   4.000000   \n",
      "1                                   4.000000   \n",
      "2                                   3.000000   \n",
      "3                                   7.500000   \n",
      "4                                   7.333333   \n",
      "\n",
      "   Total year of education completed  \\\n",
      "0                           6.500000   \n",
      "1                          11.325249   \n",
      "2                           7.883500   \n",
      "3                          13.912625   \n",
      "4                          11.666667   \n",
      "\n",
      "   No. of days stayed away from home during last 30 days  \\\n",
      "0                                                0.0       \n",
      "1                                                0.0       \n",
      "2                                                0.0       \n",
      "3                                                0.0       \n",
      "4                                                0.0       \n",
      "\n",
      "   No. of meals usually taken in a day  \\\n",
      "0                             2.000000   \n",
      "1                             3.000000   \n",
      "2                             2.666667   \n",
      "3                             2.000000   \n",
      "4                             2.333333   \n",
      "\n",
      "   No. of meals taken during last 30 days at home  \\\n",
      "0                                       60.000000   \n",
      "1                                       90.000000   \n",
      "2                                       80.000000   \n",
      "3                                       60.000000   \n",
      "4                                       69.333333   \n",
      "\n",
      "   No. of meals taken during last 30 days away home  \\\n",
      "0                                          0.000000   \n",
      "1                                          0.000000   \n",
      "2                                          0.000000   \n",
      "3                                          0.000000   \n",
      "4                                          0.666667   \n",
      "\n",
      "   flag_Whether used internet from any location during last 30 days  \n",
      "0                                                  0                 \n",
      "1                                                  1                 \n",
      "2                                                  0                 \n",
      "3                                                  1                 \n",
      "4                                                  1                 \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "                                  HH_ID  Sector  State  NSS-Region  District  \\\n",
      "0   HCES2022699591212130623068221111306       1     21         213         6   \n",
      "1   HCES2022325492191931132028219201301       2     19         193        11   \n",
      "2   HCES2022331532151510322037115101308       2     15         151         3   \n",
      "3   HCES2022622821121210923037212102315       1     12         121         9   \n",
      "4  HCES20223918022929318420110229101301       2     29         293        18   \n",
      "\n",
      "   Household Type  Religion of the head of the household  \\\n",
      "0               6                                      1   \n",
      "1               1                                      1   \n",
      "2               2                                      3   \n",
      "3               1                                      6   \n",
      "4               9                                      1   \n",
      "\n",
      "   Social Group of the head of the household  HH Size (For FDQ)  NCO_3D  ...  \\\n",
      "0                                          1                  2   931.0  ...   \n",
      "1                                          9                  1   522.0  ...   \n",
      "2                                          1                  5   411.0  ...   \n",
      "3                                          9                  6   611.0  ...   \n",
      "4                                          3                  2     NaN  ...   \n",
      "\n",
      "   Is_HH_Have_Mobile_handset  Is_HH_Have_Bicycle  \\\n",
      "0                        1.0                 1.0   \n",
      "1                        1.0                 NaN   \n",
      "2                        1.0                 NaN   \n",
      "3                        1.0                 1.0   \n",
      "4                        1.0                 NaN   \n",
      "\n",
      "   Is_HH_Have_Motorcycle_scooter  Is_HH_Have_Motorcar_jeep_van  \\\n",
      "0                            NaN                           NaN   \n",
      "1                            NaN                           NaN   \n",
      "2                            1.0                           NaN   \n",
      "3                            NaN                           NaN   \n",
      "4                            1.0                           NaN   \n",
      "\n",
      "   Is_HH_Have_Trucks  Is_HH_Have_Animal_cart  Is_HH_Have_Refrigerator  \\\n",
      "0                NaN                     NaN                      NaN   \n",
      "1                NaN                     NaN                      NaN   \n",
      "2                NaN                     NaN                      1.0   \n",
      "3                NaN                     NaN                      NaN   \n",
      "4                NaN                     NaN                      1.0   \n",
      "\n",
      "   Is_HH_Have_Washing_machine  Is_HH_Have_Airconditioner_aircooler  \\\n",
      "0                         NaN                                  NaN   \n",
      "1                         NaN                                  NaN   \n",
      "2                         1.0                                  NaN   \n",
      "3                         NaN                                  NaN   \n",
      "4                         1.0                                  NaN   \n",
      "\n",
      "   TotalExpense  \n",
      "0   2126.202544  \n",
      "1   4900.391389  \n",
      "2   6860.936595  \n",
      "3   3015.326484  \n",
      "4  11727.344423  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "                                  HH_ID  Sector  State  NSS-Region  District  \\\n",
      "0   HCES2022699591212130623068221111306       1     21         213         6   \n",
      "1   HCES2022325492191931132028219201301       2     19         193        11   \n",
      "2   HCES2022331532151510322037115101308       2     15         151         3   \n",
      "3   HCES2022622821121210923037212102315       1     12         121         9   \n",
      "4  HCES20223918022929318420110229101301       2     29         293        18   \n",
      "\n",
      "   Household Type  Religion of the head of the household  \\\n",
      "0               6                                      1   \n",
      "1               1                                      1   \n",
      "2               2                                      3   \n",
      "3               1                                      6   \n",
      "4               9                                      1   \n",
      "\n",
      "   Social Group of the head of the household  HH Size (For FDQ)  profession  \\\n",
      "0                                          1                  2        10.0   \n",
      "1                                          9                  1         6.0   \n",
      "2                                          1                  5         5.0   \n",
      "3                                          9                  6         7.0   \n",
      "4                                          3                  2         0.0   \n",
      "\n",
      "   ...  head_education_years  male_to_total_ratio  Is_couple  \\\n",
      "0  ...                     3                  0.5          2   \n",
      "1  ...                     9                  0.0          0   \n",
      "2  ...                    17                  0.4          2   \n",
      "3  ...                    10                  0.5          2   \n",
      "4  ...                    12                  0.5          2   \n",
      "\n",
      "   Highest educational level attained (code)  \\\n",
      "0                                        3.5   \n",
      "1                                        5.0   \n",
      "2                                        8.8   \n",
      "3                                        3.5   \n",
      "4                                        4.0   \n",
      "\n",
      "   Total year of education completed  \\\n",
      "0                           4.000000   \n",
      "1                           9.000000   \n",
      "2                          14.931409   \n",
      "3                           9.385682   \n",
      "4                          10.828523   \n",
      "\n",
      "   No. of days stayed away from home during last 30 days  \\\n",
      "0                                                0.0       \n",
      "1                                                0.0       \n",
      "2                                                0.0       \n",
      "3                                                0.0       \n",
      "4                                                0.0       \n",
      "\n",
      "   No. of meals usually taken in a day  \\\n",
      "0                                  3.0   \n",
      "1                                  2.0   \n",
      "2                                  3.0   \n",
      "3                                  3.0   \n",
      "4                                  3.0   \n",
      "\n",
      "   No. of meals taken during last 30 days at home  \\\n",
      "0                                       90.000000   \n",
      "1                                       60.000000   \n",
      "2                                       81.600000   \n",
      "3                                       83.333333   \n",
      "4                                       87.000000   \n",
      "\n",
      "   No. of meals taken during last 30 days away home  \\\n",
      "0                                          0.000000   \n",
      "1                                          0.000000   \n",
      "2                                          8.400000   \n",
      "3                                          6.666667   \n",
      "4                                          3.000000   \n",
      "\n",
      "   flag_Whether used internet from any location during last 30 days  \n",
      "0                                                  0                 \n",
      "1                                                  0                 \n",
      "2                                                  1                 \n",
      "3                                                  1                 \n",
      "4                                                  1                 \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "Test Household Data (df) head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52350 entries, 0 to 52349\n",
      "Data columns (total 30 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   HH_ID                 52350 non-null  object \n",
      " 1   Sector                52350 non-null  int64  \n",
      " 2   State                 52350 non-null  int64  \n",
      " 3   NSS_region            52350 non-null  int64  \n",
      " 4   District              52350 non-null  int64  \n",
      " 5   household_type        52350 non-null  int64  \n",
      " 6   head_religion         52350 non-null  int64  \n",
      " 7   head_social           52350 non-null  int64  \n",
      " 8   household_size        52350 non-null  int64  \n",
      " 9   profession            52350 non-null  float64\n",
      " 10  industry              52350 non-null  float64\n",
      " 11  mobile                52350 non-null  float64\n",
      " 12  online_activity       52350 non-null  float64\n",
      " 13  entertainment         52350 non-null  float64\n",
      " 14  vehicle               52350 non-null  float64\n",
      " 15  electronic            52350 non-null  float64\n",
      " 16  head_age              52350 non-null  int64  \n",
      " 17  head_gender           52350 non-null  int64  \n",
      " 18  head_education        52350 non-null  int64  \n",
      " 19  head_education_years  52350 non-null  int64  \n",
      " 20  male_to_total_ratio   52350 non-null  float64\n",
      " 21  Is_couple             52350 non-null  int64  \n",
      " 22  education             52350 non-null  float64\n",
      " 23  education_year        52350 non-null  float64\n",
      " 24  away_home             52350 non-null  float64\n",
      " 25  day_meal              52350 non-null  float64\n",
      " 26  home_meal             52350 non-null  float64\n",
      " 27  away_meal             52350 non-null  float64\n",
      " 28  internet_use          52350 non-null  int64  \n",
      " 29  Total_Expense         52350 non-null  float64\n",
      "dtypes: float64(15), int64(14), object(1)\n",
      "memory usage: 12.0+ MB\n",
      "None\n",
      "\n",
      "Train Household Data (df_t) head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209396 entries, 0 to 209395\n",
      "Data columns (total 30 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   HH_ID                 209396 non-null  object \n",
      " 1   Sector                209396 non-null  int64  \n",
      " 2   State                 209396 non-null  int64  \n",
      " 3   NSS_region            209396 non-null  int64  \n",
      " 4   District              209396 non-null  int64  \n",
      " 5   household_type        209396 non-null  int64  \n",
      " 6   head_religion         209396 non-null  int64  \n",
      " 7   head_social           209396 non-null  int64  \n",
      " 8   household_size        209396 non-null  int64  \n",
      " 9   profession            209396 non-null  float64\n",
      " 10  industry              209396 non-null  float64\n",
      " 11  mobile                209396 non-null  float64\n",
      " 12  online_activity       209396 non-null  float64\n",
      " 13  entertainment         209396 non-null  float64\n",
      " 14  vehicle               209396 non-null  float64\n",
      " 15  electronic            209396 non-null  float64\n",
      " 16  head_age              209396 non-null  int64  \n",
      " 17  head_gender           209396 non-null  int64  \n",
      " 18  head_education        209396 non-null  int64  \n",
      " 19  head_education_years  209396 non-null  int64  \n",
      " 20  male_to_total_ratio   209396 non-null  float64\n",
      " 21  Is_couple             209396 non-null  int64  \n",
      " 22  education             209396 non-null  float64\n",
      " 23  education_year        209396 non-null  float64\n",
      " 24  away_home             209396 non-null  float64\n",
      " 25  day_meal              209396 non-null  float64\n",
      " 26  home_meal             209396 non-null  float64\n",
      " 27  away_meal             209396 non-null  float64\n",
      " 28  internet_use          209396 non-null  int64  \n",
      " 29  Total_Expense         209396 non-null  float64\n",
      "dtypes: float64(15), int64(14), object(1)\n",
      "memory usage: 47.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def process_data(df, data2):\n",
    "    # ===== PROCESSING DF (Household Data) =====\n",
    "    \n",
    "    # 1️⃣ Overwrite one column by dividing with another column\n",
    "    COL_NUM    = 34   # column to overwrite\n",
    "    DIV_BY_COL = 8    # column to divide by\n",
    "    df.iloc[:, COL_NUM] = df.iloc[:, COL_NUM] / df.iloc[:, DIV_BY_COL]\n",
    "    print(df.head())\n",
    "    # 2️⃣ NIC processing\n",
    "    NIC_COL_IDX  = 10  # zero‑based index of your NIC column\n",
    "    nic_sections = {\n",
    "        '01': 'A - Agriculture, Forestry and Fishing',\n",
    "        '02': 'A - Agriculture, Forestry and Fishing',\n",
    "        '03': 'A - Agriculture, Forestry and Fishing',\n",
    "        '05': 'B - Mining and Quarrying',\n",
    "        '06': 'B - Mining and Quarrying',\n",
    "        '07': 'B - Mining and Quarrying',\n",
    "        '08': 'B - Mining and Quarrying',\n",
    "        '09': 'B - Mining and Quarrying',\n",
    "        '10': 'C - Manufacturing',\n",
    "        '11': 'C - Manufacturing',\n",
    "        '12': 'C - Manufacturing',\n",
    "        '13': 'C - Manufacturing',\n",
    "        '14': 'C - Manufacturing',\n",
    "        '15': 'C - Manufacturing',\n",
    "        '16': 'C - Manufacturing',\n",
    "        '17': 'C - Manufacturing',\n",
    "        '18': 'C - Manufacturing',\n",
    "        '19': 'C - Manufacturing',\n",
    "        '20': 'C - Manufacturing',\n",
    "        '21': 'C - Manufacturing',\n",
    "        '22': 'C - Manufacturing',\n",
    "        '23': 'C - Manufacturing',\n",
    "        '24': 'C - Manufacturing',\n",
    "        '25': 'C - Manufacturing',\n",
    "        '26': 'C - Manufacturing',\n",
    "        '27': 'C - Manufacturing',\n",
    "        '28': 'C - Manufacturing',\n",
    "        '29': 'C - Manufacturing',\n",
    "        '30': 'C - Manufacturing',\n",
    "        '31': 'C - Manufacturing',\n",
    "        '32': 'C - Manufacturing',\n",
    "        '33': 'C - Manufacturing',\n",
    "        '35': 'D - Electricity, Gas, Steam and Air Conditioning Supply',\n",
    "        '36': 'E - Water Supply, Sewerage, Waste Management and Remediation',\n",
    "        '37': 'E - Water Supply, Sewerage, Waste Management and Remediation',\n",
    "        '38': 'E - Water Supply, Sewerage, Waste Management and Remediation',\n",
    "        '39': 'E - Water Supply, Sewerage, Waste Management and Remediation',\n",
    "        '41': 'F - Construction',\n",
    "        '42': 'F - Construction',\n",
    "        '43': 'F - Construction',\n",
    "        '45': 'G - Wholesale and Retail Trade; Repair of Motor Vehicles and Motorcycles',\n",
    "        '46': 'G - Wholesale and Retail Trade; Repair of Motor Vehicles and Motorcycles',\n",
    "        '47': 'G - Wholesale and Retail Trade; Repair of Motor Vehicles and Motorcycles',\n",
    "        '49': 'H - Transportation and Storage',\n",
    "        '50': 'H - Transportation and Storage',\n",
    "        '51': 'H - Transportation and Storage',\n",
    "        '52': 'H - Transportation and Storage',\n",
    "        '53': 'H - Transportation and Storage',\n",
    "        '55': 'I - Accommodation and Food Service Activities',\n",
    "        '56': 'I - Accommodation and Food Service Activities',\n",
    "        '58': 'J - Information and Communication',\n",
    "        '59': 'J - Information and Communication',\n",
    "        '60': 'J - Information and Communication',\n",
    "        '61': 'J - Information and Communication',\n",
    "        '62': 'J - Information and Communication',\n",
    "        '63': 'J - Information and Communication',\n",
    "        '64': 'K - Financial and Insurance Activities',\n",
    "        '65': 'K - Financial and Insurance Activities',\n",
    "        '66': 'K - Financial and Insurance Activities',\n",
    "        '68': 'L - Real Estate Activities',\n",
    "        '69': 'M - Professional, Scientific and Technical Activities',\n",
    "        '70': 'M - Professional, Scientific and Technical Activities',\n",
    "        '71': 'M - Professional, Scientific and Technical Activities',\n",
    "        '72': 'M - Professional, Scientific and Technical Activities',\n",
    "        '73': 'M - Professional, Scientific and Technical Activities',\n",
    "        '74': 'M - Professional, Scientific and Technical Activities',\n",
    "        '75': 'M - Professional, Scientific and Technical Activities',\n",
    "        '77': 'N - Administrative and Support Service Activities',\n",
    "        '78': 'N - Administrative and Support Service Activities',\n",
    "        '79': 'N - Administrative and Support Service Activities',\n",
    "        '80': 'N - Administrative and Support Service Activities',\n",
    "        '81': 'N - Administrative and Support Service Activities',\n",
    "        '82': 'N - Administrative and Support Service Activities',\n",
    "        '84': 'O - Public Administration and Defence; Compulsory Social Security',\n",
    "        '85': 'P - Education',\n",
    "        '86': 'Q - Human Health and Social Work Activities',\n",
    "        '87': 'Q - Human Health and Social Work Activities',\n",
    "        '88': 'Q - Human Health and Social Work Activities',\n",
    "        '90': 'R - Arts, Entertainment and Recreation',\n",
    "        '91': 'R - Arts, Entertainment and Recreation',\n",
    "        '92': 'R - Arts, Entertainment and Recreation',\n",
    "        '93': 'R - Arts, Entertainment and Recreation',\n",
    "        '94': 'S - Other Service Activities',\n",
    "        '95': 'S - Other Service Activities',\n",
    "        '96': 'S - Other Service Activities',\n",
    "        '97': 'T - Activities of Households as Employers',\n",
    "        '98': 'T - Activities of Households as Employers',\n",
    "        '99': 'U - Activities of Extraterritorial Organizations and Bodies'\n",
    "    }\n",
    "    \n",
    "    # Extract first two digits, map to section and then to a numeric code\n",
    "    df[\"division\"] = df.iloc[:, NIC_COL_IDX].astype(str).str.zfill(5).str[:2]\n",
    "    df[\"section\"] = df[\"division\"].map(nic_sections)\n",
    "    unique_sections = sorted(set(nic_sections.values()))\n",
    "    section_to_num   = {sec: i+1 for i, sec in enumerate(unique_sections)}\n",
    "    df.iloc[:, NIC_COL_IDX] = df[\"section\"].map(section_to_num)\n",
    "    df.drop(columns=[\"division\", \"section\"], inplace=True)\n",
    "    col_index = 10\n",
    "    df.rename(columns={df.columns[col_index]: 'industry'}, inplace=True)\n",
    "    df['industry'].fillna(0, inplace=True)\n",
    "    \n",
    "    # 3️⃣ NCO processing: converting a 3‑digit code into a numeric professional code\n",
    "    NCO_COL_IDX  = 9  # zero‑based index of your 3‑digit NCO column\n",
    "    nco_sections = {\n",
    "        '1': 'Managers',\n",
    "        '2': 'Professionals',\n",
    "        '3': 'Technicians and Associate Professionals',\n",
    "        '4': 'Clerical Support Workers',\n",
    "        '5': 'Service and Sales Workers',\n",
    "        '6': 'Skilled Agricultural, Forestry, and Fishery Workers',\n",
    "        '7': 'Craft and Related Trades Workers',\n",
    "        '8': 'Plant and Machine Operators and Assemblers',\n",
    "        '9': 'Elementary Occupations',\n",
    "        '0': 'Armed Forces Occupations'\n",
    "    }\n",
    "    df[\"major_group\"] = df.iloc[:, NCO_COL_IDX].astype(str).str.zfill(3).str[0]\n",
    "    df[\"group_name\"] = df[\"major_group\"].map(nco_sections)\n",
    "    sorted_groups = [nco_sections[k] for k in sorted(nco_sections)]\n",
    "    group_to_num = {name: i+1 for i, name in enumerate(sorted_groups)}\n",
    "    df.iloc[:, NCO_COL_IDX] = df[\"group_name\"].map(group_to_num).fillna(0).astype(int)\n",
    "    df.rename(columns={df.columns[NCO_COL_IDX]: \"nco_group_code\"}, inplace=True)\n",
    "    df.drop(columns=[\"major_group\", \"group_name\"], inplace=True)\n",
    "    df.rename(columns={df.columns[NCO_COL_IDX]: \"profession\"}, inplace=True)\n",
    "    \n",
    "\n",
    "    # 5️⃣ Compute weighted sums for various activities/features\n",
    "    # -- online_activity\n",
    "    coef_list = [0.08599469450932685, 0.017472204136149014, -0.018403342544424033, 0.014986391813997592,\n",
    "                 0.027851679145488552, 0.01154935460641519, -0.005017965598407833, -0.0013414755683872877,\n",
    "                 -0.0037792362754634186, -0.008714205476360579, 0.010008492824308534]\n",
    "    FEATURE_INDICES = [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "    df.iloc[:, FEATURE_INDICES] = df.iloc[:, FEATURE_INDICES].fillna(0)\n",
    "    df[\"online_activity\"] = df.iloc[:, FEATURE_INDICES].dot(coef_list)\n",
    "    df.drop(columns=df.columns[FEATURE_INDICES], inplace=True)\n",
    "    \n",
    "    # -- entertainment\n",
    "    coef_list1 = [0.22190073014586958, 0.025360494795706734, 0.2682093576723438]\n",
    "    FEATURE_INDICES = [11, 12, 13]\n",
    "    df.iloc[:, FEATURE_INDICES] = df.iloc[:, FEATURE_INDICES].fillna(0)\n",
    "    df[\"entertainment\"] = df.iloc[:, FEATURE_INDICES].dot(coef_list1)\n",
    "    df.drop(columns=df.columns[FEATURE_INDICES], inplace=True)\n",
    "    \n",
    "    # -- vehicle\n",
    "    df.iloc[:, 11] = df.iloc[:, 11].fillna(0)\n",
    "    coef_list2 = [-0.17588991633308818, 0.16057196556897707, 0.24053641154395702,\n",
    "                  0.00976584351888473, -0.01487601462035179]\n",
    "    FEATURE_INDICES = [12, 13, 14, 15, 16]\n",
    "    df.iloc[:, FEATURE_INDICES] = df.iloc[:, FEATURE_INDICES].fillna(0)\n",
    "    df[\"vehicle\"] = df.iloc[:, FEATURE_INDICES].dot(coef_list2)\n",
    "    df.drop(columns=df.columns[FEATURE_INDICES], inplace=True)\n",
    "    \n",
    "    # -- electronic\n",
    "    coef_list3 = [0.2759033345016436, 0.23119865931256456, 0.010382606801460331]\n",
    "    FEATURE_INDICES = [12, 13, 14]\n",
    "    df.iloc[:, FEATURE_INDICES] = df.iloc[:, FEATURE_INDICES].fillna(0)\n",
    "    df[\"electronic\"] = df.iloc[:, FEATURE_INDICES].dot(coef_list3)\n",
    "    df.drop(columns=df.columns[FEATURE_INDICES], inplace=True)\n",
    "    df.rename(columns={df.columns[11]: \"mobile\"}, inplace=True)\n",
    "     #4️⃣ Reordering: moving a column from its current position\n",
    "    col_name = df.columns[12]\n",
    "    df[col_name] = df.pop(col_name)\n",
    "    # ===== PROCESSING DATA2 (Person‑Level Data) =====\n",
    "    \n",
    "    # -- Marital status conversion: 2→1, others→0\n",
    "    data2['Marital Status (code)'] = (data2['Marital Status (code)'] == 2).astype(int)\n",
    "    data2.rename(columns={'Marital Status (code)': 'Is_couple'}, inplace=True)\n",
    "    \n",
    "    # -- Education: fill missing with group mean and overall mean\n",
    "    data2['Total year of education completed'] = data2['Total year of education completed']\\\n",
    "        .fillna(data2.groupby('Highest educational level attained (code)')['Total year of education completed'].transform('mean'))\\\n",
    "        .fillna(data2['Total year of education completed'].mean())\n",
    "    \n",
    "    # -- Internet usage: binary conversion\n",
    "    data2['Whether used internet from any location during last 30 days'] = data2['Whether used internet from any location during last 30 days'].eq(1).astype(int)\n",
    "    \n",
    "    # -- Days stayed away: fill NaNs with 0\n",
    "    data2['No. of days stayed away from home during last 30 days'].fillna(0, inplace=True)\n",
    "    \n",
    "    # -- Meals taken: fill missing meals with mode and 0\n",
    "    mode_val = data2['No. of meals usually taken in a day'].mode().iloc[0]\n",
    "    data2['No. of meals usually taken in a day'].fillna(mode_val, inplace=True)\n",
    "    data2['No. of meals taken during last 30 days at home'].fillna(0, inplace=True)\n",
    "    start, end = 11, 15\n",
    "    data2['No. of meals taken during last 30 days away home'] = data2.iloc[:, start:end].fillna(0).sum(axis=1)\n",
    "    data2.drop(columns=data2.columns[start:end], inplace=True)\n",
    "    \n",
    "    # -- Drop Person Srl No. column\n",
    "    data2.drop(columns=['Person Srl No.'], inplace=True)\n",
    "    \n",
    "    # ===== AGGREGATING PERSON‑LEVEL DATA INTO DF =====\n",
    "    \n",
    "    # 1. Merge head person data\n",
    "    df_heads = data2[data2[\"Relation to head (code)\"] == 1]\n",
    "    df_heads = df_heads[[\"HH_ID\", \"Age(in years)\", \"Gender\", \"Highest educational level attained (code)\",\n",
    "                         \"Total year of education completed\"]].rename(columns={\n",
    "                             \"Age(in years)\": \"head_age\",\n",
    "                             \"Gender\": \"head_gender\",\n",
    "                             \"Highest educational level attained (code)\": \"head_education\",\n",
    "                             \"Total year of education completed\": \"head_education_years\"\n",
    "                         })\n",
    "    df = df.merge(df_heads, on=\"HH_ID\", how=\"left\")\n",
    "    df[\"head_education_years\"] = np.ceil(df[\"head_education_years\"]).astype(int)\n",
    "    \n",
    "    # 2. Calculate male counts and ratio per family\n",
    "    male_counts = data2[data2.iloc[:, 2] == 1].groupby(\"HH_ID\").size().rename(\"male_count\")\n",
    "    df = df.merge(male_counts, on=\"HH_ID\", how=\"left\")\n",
    "    df[\"male_count\"].fillna(0, inplace=True)\n",
    "    df[\"male_to_total_ratio\"] = df[\"male_count\"] / df[\"HH Size (For FDQ)\"]\n",
    "    df.drop(columns=\"male_count\", inplace=True)\n",
    "    \n",
    "    # 3. Aggregate selected columns by sum\n",
    "    idx = [4]\n",
    "    cols = data2.columns[idx]\n",
    "    agg = data2.groupby('HH_ID')[cols].sum().reset_index()\n",
    "    df = df.merge(agg, on='HH_ID', how='left')\n",
    "    \n",
    "    # 4. Aggregate selected columns by mean\n",
    "    idx = [5, 6, 8, 9, 10, 11]\n",
    "    cols = data2.columns[idx]\n",
    "    agg = data2.groupby('HH_ID')[cols].mean().reset_index()\n",
    "    df = df.merge(agg, on='HH_ID', how='left')\n",
    "    \n",
    "    # 5. Flag aggregation: any True becomes 1\n",
    "    idx = [7]\n",
    "    cols = data2.columns[idx]\n",
    "    agg = data2.groupby('HH_ID')[cols].any().astype(int).add_prefix('flag_').reset_index()\n",
    "    df = df.merge(agg, on='HH_ID', how='left')\n",
    "    flag_cols = agg.columns.drop('HH_ID')\n",
    "    df[flag_cols] = df[flag_cols].fillna(0).astype(int)\n",
    "    print(df.head())\n",
    "    # 6. Reorder and rename columns in df\n",
    "    col_name = df.columns[16]\n",
    "    df[col_name] = df.pop(col_name)\n",
    "    df.rename(columns={df.columns[29]: 'Total_Expense'}, inplace=True)\n",
    "    df.rename(columns={df.columns[28]: 'internet_use'}, inplace=True)\n",
    "    df.rename(columns={df.columns[27]: 'away_meal'}, inplace=True)\n",
    "    df.rename(columns={df.columns[26]: 'home_meal'}, inplace=True)\n",
    "    df.rename(columns={df.columns[25]: 'day_meal'}, inplace=True)\n",
    "    df.rename(columns={df.columns[24]: 'away_home'}, inplace=True)\n",
    "    df.rename(columns={df.columns[23]: 'education_year'}, inplace=True)\n",
    "    df.rename(columns={df.columns[22]: 'education'}, inplace=True)\n",
    "    df.rename(columns={df.columns[8]: 'household_size'}, inplace=True)\n",
    "    df.rename(columns={df.columns[7]: 'head_social'}, inplace=True)\n",
    "    df.rename(columns={df.columns[6]: 'head_religion'}, inplace=True)\n",
    "    df.rename(columns={df.columns[5]: 'household_type'}, inplace=True)\n",
    "    df.rename(columns={df.columns[3]: 'NSS_region'}, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ===== APPLYING THE FUNCTION TO BOTH TRAIN AND TEST DATA =====\n",
    "\n",
    "# Assuming you already have the following DataFrames defined:\n",
    "# test_data_hh, test_data_per, train_data_hh, train_data_per\n",
    "\n",
    "# Create copies to avoid modifying the original DataFrames\n",
    "processed_df= process_data(test_data_hh.copy(), test_data_per.copy())\n",
    "processed_df_t = process_data(train_data_hh.copy(), train_data_per.copy())\n",
    "# Optional: Verify the results\n",
    "print(\"Test Household Data (df) head:\")\n",
    "print(processed_df.info())\n",
    "\n",
    "print(\"\\nTrain Household Data (df_t) head:\")\n",
    "print(processed_df_t.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52350 entries, 0 to 52349\n",
      "Data columns (total 30 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   HH_ID                 52350 non-null  object \n",
      " 1   Sector                52350 non-null  int64  \n",
      " 2   State                 52350 non-null  int64  \n",
      " 3   NSS_region            52350 non-null  int64  \n",
      " 4   District              52350 non-null  int64  \n",
      " 5   household_type        52350 non-null  int64  \n",
      " 6   head_religion         52350 non-null  int64  \n",
      " 7   head_social           52350 non-null  int64  \n",
      " 8   household_size        52350 non-null  int64  \n",
      " 9   profession            52350 non-null  float64\n",
      " 10  industry              52350 non-null  float64\n",
      " 11  mobile                52350 non-null  float64\n",
      " 12  online_activity       52350 non-null  float64\n",
      " 13  entertainment         52350 non-null  float64\n",
      " 14  vehicle               52350 non-null  float64\n",
      " 15  electronic            52350 non-null  float64\n",
      " 16  head_age              52350 non-null  int64  \n",
      " 17  head_gender           52350 non-null  int64  \n",
      " 18  head_education        52350 non-null  int64  \n",
      " 19  head_education_years  52350 non-null  int64  \n",
      " 20  male_to_total_ratio   52350 non-null  float64\n",
      " 21  Is_couple             52350 non-null  int64  \n",
      " 22  education             52350 non-null  float64\n",
      " 23  education_year        52350 non-null  float64\n",
      " 24  away_home             52350 non-null  float64\n",
      " 25  day_meal              52350 non-null  float64\n",
      " 26  home_meal             52350 non-null  float64\n",
      " 27  away_meal             52350 non-null  float64\n",
      " 28  internet_use          52350 non-null  int64  \n",
      " 29  Total_Expense         52350 non-null  float64\n",
      "dtypes: float64(15), int64(14), object(1)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "processed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from demographic_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error  # optional, if you need further metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "class HouseholdDemographicModel:\n",
    "    def __init__(self):\n",
    "        self.features = [\n",
    "            \"total_persons\", \"num_infants\", \"num_adults\", \"infant_dependency_ratio\",\n",
    "            \"num_dependents\", \"overall_dependency_ratio\", \"avg_age_y\", \"std_age_y\",\n",
    "            \"min_age_y\", \"max_age_y\", \"avg_education\"\n",
    "        ]\n",
    "        self.lr_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('lr', LinearRegression())\n",
    "        ])\n",
    "        self.rf_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('rf', RandomForestRegressor(random_state=42))\n",
    "        ])\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_household_stats(group):\n",
    "        total_persons = group.shape[0]\n",
    "        num_infants = (group[\"Age(in years)\"] < 5).sum()\n",
    "        num_adults = (group[\"Age(in years)\"] >= 18).sum()\n",
    "        infant_dependency_ratio = num_infants / num_adults if num_adults > 0 else 0.0\n",
    "        num_dependents = ((group[\"Age(in years)\"] < 18) | (group[\"Age(in years)\"] >= 65)).sum()\n",
    "        overall_dependency_ratio = num_dependents / total_persons if total_persons > 0 else 0.0\n",
    "        avg_age = group[\"Age(in years)\"].mean()\n",
    "        std_age = group[\"Age(in years)\"].std()\n",
    "        min_age = group[\"Age(in years)\"].min()\n",
    "        max_age = group[\"Age(in years)\"].max()\n",
    "        avg_education = group[\"Total year of education completed\"].mean()\n",
    "        \n",
    "        return pd.Series({\n",
    "            \"total_persons\": total_persons,\n",
    "            \"num_infants\": num_infants,\n",
    "            \"num_adults\": num_adults,\n",
    "            \"infant_dependency_ratio\": infant_dependency_ratio,\n",
    "            \"num_dependents\": num_dependents,\n",
    "            \"overall_dependency_ratio\": overall_dependency_ratio,\n",
    "            \"avg_age\": avg_age,\n",
    "            \"std_age\": std_age,\n",
    "            \"min_age\": min_age,\n",
    "            \"max_age\": max_age,\n",
    "            \"avg_education\": avg_education\n",
    "        })\n",
    "\n",
    "    def preprocess(self, df_person, df_household):\n",
    "        # Compute household-level demographic stats from person-level data.\n",
    "        household_stats = df_person.groupby(\"HH_ID\").apply(self.compute_household_stats).reset_index()\n",
    "        # Rename columns for consistency.\n",
    "        household_stats = household_stats.rename(columns={\n",
    "            \"avg_age\": \"avg_age_y\",\n",
    "            \"std_age\": \"std_age_y\",\n",
    "            \"min_age\": \"min_age_y\",\n",
    "            \"max_age\": \"max_age_y\"\n",
    "        })\n",
    "        # Merge with household data.\n",
    "        df_merged = pd.merge(df_household, household_stats, on=\"HH_ID\", how=\"left\")\n",
    "        # Fill missing values for features and target.\n",
    "        df_merged[self.features + [\"TotalExpense\"]] = df_merged[self.features + [\"TotalExpense\"]].fillna(0)\n",
    "        return df_merged\n",
    "\n",
    "    def fit(self, df_person_train, df_household_train):\n",
    "        df_merged = self.preprocess(df_person_train, df_household_train)\n",
    "        X_train = df_merged[self.features]\n",
    "        y_train = df_merged[\"TotalExpense\"]\n",
    "        self.lr_pipeline.fit(X_train, y_train)\n",
    "        self.rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, df_person, df_household):\n",
    "        df_merged = self.preprocess(df_person, df_household)\n",
    "        X = df_merged[self.features]\n",
    "        df_merged[\"demographic_param_lr\"] = self.lr_pipeline.predict(X)\n",
    "        df_merged[\"demographic_param_rf\"] = self.rf_pipeline.predict(X)\n",
    "        return df_merged\n",
    "\n",
    "    def evaluate(self, df_person, df_household):\n",
    "        df_merged = self.preprocess(df_person, df_household)\n",
    "        X = df_merged[self.features]\n",
    "        y = df_merged[\"TotalExpense\"]\n",
    "        pred_lr = self.lr_pipeline.predict(X)\n",
    "        pred_rf = self.rf_pipeline.predict(X)\n",
    "        lr_corr = pd.Series(pred_lr).corr(y)\n",
    "        rf_corr = pd.Series(pred_rf).corr(y)\n",
    "        df_merged[\"demographic_param_lr\"] = pred_lr\n",
    "        df_merged[\"demographic_param_rf\"] = pred_rf\n",
    "        return {\"lr_corr\": lr_corr, \"rf_corr\": rf_corr}, df_merged\n",
    "\n",
    "    def save_model(self, filename=\"demographic_model.pkl\"):\n",
    "        joblib.dump(self, filename)\n",
    "        print(f\"Model saved as {filename}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(filename=\"demographic_model.pkl\"):\n",
    "        model = joblib.load(filename)\n",
    "        print(f\"Model loaded from {filename}\")\n",
    "        return model\n",
    "if __name__ == \"__main__\":\n",
    "    # Define file paths for test data.\n",
    "  \n",
    "\n",
    "    # Load test data.\n",
    "    df_person_test = pd.read_csv(test_data_per_path)\n",
    "    df_household_test = pd.read_csv(test_data_hh_path)\n",
    "\n",
    "    # Load the saved model.\n",
    "    demo_model = HouseholdDemographicModel.load_model(\"demographic_model.pkl\")\n",
    "\n",
    "    processed_df = pd.merge(processed_df,demo_model.predict(df_person_test, df_household_test)[['HH_ID','demographic_param_lr']],on='HH_ID',how='left')\n",
    "\n",
    "    processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded from trained_models.pkl\n",
      "\n",
      "Testing for States: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
      "\n",
      "Processing State: 1\n",
      "State 1 - Test Correlation (Online model): 0.5299\n",
      "State 1 - Test Correlation (Assert model): 0.6053\n",
      "\n",
      "Processing State: 2\n",
      "State 2 - Test Correlation (Online model): 0.2853\n",
      "State 2 - Test Correlation (Assert model): 0.5114\n",
      "\n",
      "Processing State: 3\n",
      "State 3 - Test Correlation (Online model): 0.3019\n",
      "State 3 - Test Correlation (Assert model): 0.4930\n",
      "\n",
      "Processing State: 4\n",
      "State 4 - Test Correlation (Online model): 0.3250\n",
      "State 4 - Test Correlation (Assert model): 0.7216\n",
      "\n",
      "Processing State: 5\n",
      "State 5 - Test Correlation (Online model): 0.4174\n",
      "State 5 - Test Correlation (Assert model): 0.6621\n",
      "\n",
      "Processing State: 6\n",
      "State 6 - Test Correlation (Online model): 0.4537\n",
      "State 6 - Test Correlation (Assert model): 0.6003\n",
      "\n",
      "Processing State: 7\n",
      "State 7 - Test Correlation (Online model): 0.4465\n",
      "State 7 - Test Correlation (Assert model): 0.6349\n",
      "\n",
      "Processing State: 8\n",
      "State 8 - Test Correlation (Online model): 0.2313\n",
      "State 8 - Test Correlation (Assert model): 0.5297\n",
      "\n",
      "Processing State: 9\n",
      "State 9 - Test Correlation (Online model): 0.4284\n",
      "State 9 - Test Correlation (Assert model): 0.5922\n",
      "\n",
      "Processing State: 10\n",
      "State 10 - Test Correlation (Online model): 0.2625\n",
      "State 10 - Test Correlation (Assert model): 0.5060\n",
      "\n",
      "Processing State: 11\n",
      "State 11 - Test Correlation (Online model): 0.2879\n",
      "State 11 - Test Correlation (Assert model): 0.4191\n",
      "\n",
      "Processing State: 12\n",
      "State 12 - Test Correlation (Online model): 0.3178\n",
      "State 12 - Test Correlation (Assert model): 0.6310\n",
      "\n",
      "Processing State: 13\n",
      "State 13 - Test Correlation (Online model): 0.3245\n",
      "State 13 - Test Correlation (Assert model): 0.7333\n",
      "\n",
      "Processing State: 14\n",
      "State 14 - Test Correlation (Online model): 0.2627\n",
      "State 14 - Test Correlation (Assert model): 0.5146\n",
      "\n",
      "Processing State: 15\n",
      "State 15 - Test Correlation (Online model): 0.3921\n",
      "State 15 - Test Correlation (Assert model): 0.6216\n",
      "\n",
      "Processing State: 16\n",
      "State 16 - Test Correlation (Online model): 0.3086\n",
      "State 16 - Test Correlation (Assert model): 0.5246\n",
      "\n",
      "Processing State: 17\n",
      "State 17 - Test Correlation (Online model): 0.4417\n",
      "State 17 - Test Correlation (Assert model): 0.5798\n",
      "\n",
      "Processing State: 18\n",
      "State 18 - Test Correlation (Online model): 0.3876\n",
      "State 18 - Test Correlation (Assert model): 0.5333\n",
      "\n",
      "Processing State: 19\n",
      "State 19 - Test Correlation (Online model): 0.5185\n",
      "State 19 - Test Correlation (Assert model): 0.6887\n",
      "\n",
      "Processing State: 20\n",
      "State 20 - Test Correlation (Online model): 0.3598\n",
      "State 20 - Test Correlation (Assert model): 0.6384\n",
      "\n",
      "Processing State: 21\n",
      "State 21 - Test Correlation (Online model): 0.4207\n",
      "State 21 - Test Correlation (Assert model): 0.7137\n",
      "\n",
      "Processing State: 22\n",
      "State 22 - Test Correlation (Online model): 0.5144\n",
      "State 22 - Test Correlation (Assert model): 0.7354\n",
      "\n",
      "Processing State: 23\n",
      "State 23 - Test Correlation (Online model): 0.4616\n",
      "State 23 - Test Correlation (Assert model): 0.6331\n",
      "\n",
      "Processing State: 24\n",
      "State 24 - Test Correlation (Online model): 0.3696\n",
      "State 24 - Test Correlation (Assert model): 0.6131\n",
      "\n",
      "Processing State: 25\n",
      "State 25 - Test Correlation (Online model): 0.0939\n",
      "State 25 - Test Correlation (Assert model): 0.7338\n",
      "\n",
      "Processing State: 27\n",
      "State 27 - Test Correlation (Online model): 0.4005\n",
      "State 27 - Test Correlation (Assert model): 0.5719\n",
      "\n",
      "Processing State: 28\n",
      "State 28 - Test Correlation (Online model): 0.3634\n",
      "State 28 - Test Correlation (Assert model): 0.6306\n",
      "\n",
      "Processing State: 29\n",
      "State 29 - Test Correlation (Online model): 0.4688\n",
      "State 29 - Test Correlation (Assert model): 0.6152\n",
      "\n",
      "Processing State: 30\n",
      "State 30 - Test Correlation (Online model): 0.3664\n",
      "State 30 - Test Correlation (Assert model): 0.5550\n",
      "\n",
      "Processing State: 31\n",
      "State 31 - Test Correlation (Online model): -0.0017\n",
      "State 31 - Test Correlation (Assert model): 0.4683\n",
      "\n",
      "Processing State: 32\n",
      "State 32 - Test Correlation (Online model): 0.2284\n",
      "State 32 - Test Correlation (Assert model): 0.5012\n",
      "\n",
      "Processing State: 33\n",
      "State 33 - Test Correlation (Online model): 0.3678\n",
      "State 33 - Test Correlation (Assert model): 0.6315\n",
      "\n",
      "Processing State: 34\n",
      "State 34 - Test Correlation (Online model): 0.2875\n",
      "State 34 - Test Correlation (Assert model): 0.5343\n",
      "\n",
      "Processing State: 35\n",
      "State 35 - Test Correlation (Online model): 0.5802\n",
      "State 35 - Test Correlation (Assert model): 0.5184\n",
      "\n",
      "Processing State: 36\n",
      "State 36 - Test Correlation (Online model): 0.3443\n",
      "State 36 - Test Correlation (Assert model): 0.6337\n",
      "\n",
      "Processing State: 37\n",
      "State 37 - Test Correlation (Online model): 0.3527\n",
      "State 37 - Test Correlation (Assert model): 0.7050\n",
      "\n",
      "Combined Testing Correlations:\n",
      "Overall Online model correlation: 0.4643\n",
      "Overall Assert model correlation: 0.6380\n",
      "\n",
      "Test features head:\n",
      "                                  HH_ID  online_constant  having_constant\n",
      "0   HCES2022619881191951823044219131316     13174.982789      7910.828444\n",
      "1   HCES2022617721191931723197219202205     25297.325340     12442.632511\n",
      "2   HCES2022632771101011022015110131311     17113.036206     13708.567553\n",
      "3   HCES2022357832080822112037108101306     21006.100927     24943.696225\n",
      "4  HCES20226869012727230232010227422206     18369.354532     16728.275232\n",
      "\n",
      "Testing for States: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
      "\n",
      "Processing State: 1\n",
      "State 1 - Test Correlation (Online model): 0.5299\n",
      "State 1 - Test Correlation (Assert model): 0.6053\n",
      "\n",
      "Processing State: 2\n",
      "State 2 - Test Correlation (Online model): 0.2853\n",
      "State 2 - Test Correlation (Assert model): 0.5114\n",
      "\n",
      "Processing State: 3\n",
      "State 3 - Test Correlation (Online model): 0.3019\n",
      "State 3 - Test Correlation (Assert model): 0.4930\n",
      "\n",
      "Processing State: 4\n",
      "State 4 - Test Correlation (Online model): 0.3250\n",
      "State 4 - Test Correlation (Assert model): 0.7216\n",
      "\n",
      "Processing State: 5\n",
      "State 5 - Test Correlation (Online model): 0.4174\n",
      "State 5 - Test Correlation (Assert model): 0.6621\n",
      "\n",
      "Processing State: 6\n",
      "State 6 - Test Correlation (Online model): 0.4537\n",
      "State 6 - Test Correlation (Assert model): 0.6003\n",
      "\n",
      "Processing State: 7\n",
      "State 7 - Test Correlation (Online model): 0.4465\n",
      "State 7 - Test Correlation (Assert model): 0.6349\n",
      "\n",
      "Processing State: 8\n",
      "State 8 - Test Correlation (Online model): 0.2313\n",
      "State 8 - Test Correlation (Assert model): 0.5297\n",
      "\n",
      "Processing State: 9\n",
      "State 9 - Test Correlation (Online model): 0.4284\n",
      "State 9 - Test Correlation (Assert model): 0.5922\n",
      "\n",
      "Processing State: 10\n",
      "State 10 - Test Correlation (Online model): 0.2625\n",
      "State 10 - Test Correlation (Assert model): 0.5060\n",
      "\n",
      "Processing State: 11\n",
      "State 11 - Test Correlation (Online model): 0.2879\n",
      "State 11 - Test Correlation (Assert model): 0.4191\n",
      "\n",
      "Processing State: 12\n",
      "State 12 - Test Correlation (Online model): 0.3178\n",
      "State 12 - Test Correlation (Assert model): 0.6310\n",
      "\n",
      "Processing State: 13\n",
      "State 13 - Test Correlation (Online model): 0.3245\n",
      "State 13 - Test Correlation (Assert model): 0.7333\n",
      "\n",
      "Processing State: 14\n",
      "State 14 - Test Correlation (Online model): 0.2627\n",
      "State 14 - Test Correlation (Assert model): 0.5146\n",
      "\n",
      "Processing State: 15\n",
      "State 15 - Test Correlation (Online model): 0.3921\n",
      "State 15 - Test Correlation (Assert model): 0.6216\n",
      "\n",
      "Processing State: 16\n",
      "State 16 - Test Correlation (Online model): 0.3086\n",
      "State 16 - Test Correlation (Assert model): 0.5246\n",
      "\n",
      "Processing State: 17\n",
      "State 17 - Test Correlation (Online model): 0.4417\n",
      "State 17 - Test Correlation (Assert model): 0.5798\n",
      "\n",
      "Processing State: 18\n",
      "State 18 - Test Correlation (Online model): 0.3876\n",
      "State 18 - Test Correlation (Assert model): 0.5333\n",
      "\n",
      "Processing State: 19\n",
      "State 19 - Test Correlation (Online model): 0.5185\n",
      "State 19 - Test Correlation (Assert model): 0.6887\n",
      "\n",
      "Processing State: 20\n",
      "State 20 - Test Correlation (Online model): 0.3598\n",
      "State 20 - Test Correlation (Assert model): 0.6384\n",
      "\n",
      "Processing State: 21\n",
      "State 21 - Test Correlation (Online model): 0.4207\n",
      "State 21 - Test Correlation (Assert model): 0.7137\n",
      "\n",
      "Processing State: 22\n",
      "State 22 - Test Correlation (Online model): 0.5144\n",
      "State 22 - Test Correlation (Assert model): 0.7354\n",
      "\n",
      "Processing State: 23\n",
      "State 23 - Test Correlation (Online model): 0.4616\n",
      "State 23 - Test Correlation (Assert model): 0.6331\n",
      "\n",
      "Processing State: 24\n",
      "State 24 - Test Correlation (Online model): 0.3696\n",
      "State 24 - Test Correlation (Assert model): 0.6131\n",
      "\n",
      "Processing State: 25\n",
      "State 25 - Test Correlation (Online model): 0.0939\n",
      "State 25 - Test Correlation (Assert model): 0.7338\n",
      "\n",
      "Processing State: 27\n",
      "State 27 - Test Correlation (Online model): 0.4005\n",
      "State 27 - Test Correlation (Assert model): 0.5719\n",
      "\n",
      "Processing State: 28\n",
      "State 28 - Test Correlation (Online model): 0.3634\n",
      "State 28 - Test Correlation (Assert model): 0.6306\n",
      "\n",
      "Processing State: 29\n",
      "State 29 - Test Correlation (Online model): 0.4688\n",
      "State 29 - Test Correlation (Assert model): 0.6152\n",
      "\n",
      "Processing State: 30\n",
      "State 30 - Test Correlation (Online model): 0.3664\n",
      "State 30 - Test Correlation (Assert model): 0.5550\n",
      "\n",
      "Processing State: 31\n",
      "State 31 - Test Correlation (Online model): -0.0017\n",
      "State 31 - Test Correlation (Assert model): 0.4683\n",
      "\n",
      "Processing State: 32\n",
      "State 32 - Test Correlation (Online model): 0.2284\n",
      "State 32 - Test Correlation (Assert model): 0.5012\n",
      "\n",
      "Processing State: 33\n",
      "State 33 - Test Correlation (Online model): 0.3678\n",
      "State 33 - Test Correlation (Assert model): 0.6315\n",
      "\n",
      "Processing State: 34\n",
      "State 34 - Test Correlation (Online model): 0.2875\n",
      "State 34 - Test Correlation (Assert model): 0.5343\n",
      "\n",
      "Processing State: 35\n",
      "State 35 - Test Correlation (Online model): 0.5802\n",
      "State 35 - Test Correlation (Assert model): 0.5184\n",
      "\n",
      "Processing State: 36\n",
      "State 36 - Test Correlation (Online model): 0.3443\n",
      "State 36 - Test Correlation (Assert model): 0.6337\n",
      "\n",
      "Processing State: 37\n",
      "State 37 - Test Correlation (Online model): 0.3527\n",
      "State 37 - Test Correlation (Assert model): 0.7050\n",
      "\n",
      "Combined Testing Correlations:\n",
      "Overall Online model correlation: 0.4643\n",
      "Overall Assert model correlation: 0.6380\n",
      "\n",
      "Testing for States: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
      "\n",
      "Processing State: 1\n",
      "State 1 - Test Correlation (Online model): 0.4842\n",
      "State 1 - Test Correlation (Assert model): 0.6394\n",
      "\n",
      "Processing State: 2\n",
      "State 2 - Test Correlation (Online model): 0.4186\n",
      "State 2 - Test Correlation (Assert model): 0.5536\n",
      "\n",
      "Processing State: 3\n",
      "State 3 - Test Correlation (Online model): 0.4647\n",
      "State 3 - Test Correlation (Assert model): 0.5504\n",
      "\n",
      "Processing State: 4\n",
      "State 4 - Test Correlation (Online model): 0.5780\n",
      "State 4 - Test Correlation (Assert model): 0.7634\n",
      "\n",
      "Processing State: 5\n",
      "State 5 - Test Correlation (Online model): 0.4919\n",
      "State 5 - Test Correlation (Assert model): 0.6229\n",
      "\n",
      "Processing State: 6\n",
      "State 6 - Test Correlation (Online model): 0.5920\n",
      "State 6 - Test Correlation (Assert model): 0.6197\n",
      "\n",
      "Processing State: 7\n",
      "State 7 - Test Correlation (Online model): 0.4907\n",
      "State 7 - Test Correlation (Assert model): 0.6278\n",
      "\n",
      "Processing State: 8\n",
      "State 8 - Test Correlation (Online model): 0.3143\n",
      "State 8 - Test Correlation (Assert model): 0.4752\n",
      "\n",
      "Processing State: 9\n",
      "State 9 - Test Correlation (Online model): 0.4765\n",
      "State 9 - Test Correlation (Assert model): 0.6410\n",
      "\n",
      "Processing State: 10\n",
      "State 10 - Test Correlation (Online model): 0.3564\n",
      "State 10 - Test Correlation (Assert model): 0.5694\n",
      "\n",
      "Processing State: 11\n",
      "State 11 - Test Correlation (Online model): 0.4789\n",
      "State 11 - Test Correlation (Assert model): 0.4500\n",
      "\n",
      "Processing State: 12\n",
      "State 12 - Test Correlation (Online model): 0.4383\n",
      "State 12 - Test Correlation (Assert model): 0.5775\n",
      "\n",
      "Processing State: 13\n",
      "State 13 - Test Correlation (Online model): 0.5100\n",
      "State 13 - Test Correlation (Assert model): 0.6543\n",
      "\n",
      "Processing State: 14\n",
      "State 14 - Test Correlation (Online model): 0.3855\n",
      "State 14 - Test Correlation (Assert model): 0.5607\n",
      "\n",
      "Processing State: 15\n",
      "State 15 - Test Correlation (Online model): 0.4487\n",
      "State 15 - Test Correlation (Assert model): 0.6439\n",
      "\n",
      "Processing State: 16\n",
      "State 16 - Test Correlation (Online model): 0.4177\n",
      "State 16 - Test Correlation (Assert model): 0.5685\n",
      "\n",
      "Processing State: 17\n",
      "State 17 - Test Correlation (Online model): 0.4677\n",
      "State 17 - Test Correlation (Assert model): 0.6985\n",
      "\n",
      "Processing State: 18\n",
      "State 18 - Test Correlation (Online model): 0.4766\n",
      "State 18 - Test Correlation (Assert model): 0.6581\n",
      "\n",
      "Processing State: 19\n",
      "State 19 - Test Correlation (Online model): 0.4715\n",
      "State 19 - Test Correlation (Assert model): 0.5995\n",
      "\n",
      "Processing State: 20\n",
      "State 20 - Test Correlation (Online model): 0.4239\n",
      "State 20 - Test Correlation (Assert model): 0.6267\n",
      "\n",
      "Processing State: 21\n",
      "State 21 - Test Correlation (Online model): 0.5440\n",
      "State 21 - Test Correlation (Assert model): 0.7180\n",
      "\n",
      "Processing State: 22\n",
      "State 22 - Test Correlation (Online model): 0.5357\n",
      "State 22 - Test Correlation (Assert model): 0.7560\n",
      "\n",
      "Processing State: 23\n",
      "State 23 - Test Correlation (Online model): 0.4563\n",
      "State 23 - Test Correlation (Assert model): 0.6456\n",
      "\n",
      "Processing State: 24\n",
      "State 24 - Test Correlation (Online model): 0.4074\n",
      "State 24 - Test Correlation (Assert model): 0.6127\n",
      "\n",
      "Processing State: 25\n",
      "State 25 - Test Correlation (Online model): 0.4417\n",
      "State 25 - Test Correlation (Assert model): 0.7503\n",
      "\n",
      "Processing State: 27\n",
      "State 27 - Test Correlation (Online model): 0.4346\n",
      "State 27 - Test Correlation (Assert model): 0.5862\n",
      "\n",
      "Processing State: 28\n",
      "State 28 - Test Correlation (Online model): 0.3796\n",
      "State 28 - Test Correlation (Assert model): 0.6033\n",
      "\n",
      "Processing State: 29\n",
      "State 29 - Test Correlation (Online model): 0.4589\n",
      "State 29 - Test Correlation (Assert model): 0.6437\n",
      "\n",
      "Processing State: 30\n",
      "State 30 - Test Correlation (Online model): 0.5023\n",
      "State 30 - Test Correlation (Assert model): 0.5749\n",
      "\n",
      "Processing State: 31\n",
      "State 31 - Test Correlation (Online model): 0.1957\n",
      "State 31 - Test Correlation (Assert model): 0.4498\n",
      "\n",
      "Processing State: 32\n",
      "State 32 - Test Correlation (Online model): 0.3722\n",
      "State 32 - Test Correlation (Assert model): 0.5128\n",
      "\n",
      "Processing State: 33\n",
      "State 33 - Test Correlation (Online model): 0.4069\n",
      "State 33 - Test Correlation (Assert model): 0.6195\n",
      "\n",
      "Processing State: 34\n",
      "State 34 - Test Correlation (Online model): 0.3538\n",
      "State 34 - Test Correlation (Assert model): 0.6532\n",
      "\n",
      "Processing State: 35\n",
      "State 35 - Test Correlation (Online model): 0.6276\n",
      "State 35 - Test Correlation (Assert model): 0.6144\n",
      "\n",
      "Processing State: 36\n",
      "State 36 - Test Correlation (Online model): 0.4913\n",
      "State 36 - Test Correlation (Assert model): 0.6735\n",
      "\n",
      "Processing State: 37\n",
      "State 37 - Test Correlation (Online model): 0.4011\n",
      "State 37 - Test Correlation (Assert model): 0.6675\n",
      "\n",
      "Combined Testing Correlations:\n",
      "Overall Online model correlation: 0.5131\n",
      "Overall Assert model correlation: 0.6445\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def train_models(train_csv, save_model_path=\"trained_models.pkl\"):\n",
    "    \"\"\"\n",
    "    Trains state-wise linear regression models (with polynomial features) on the training CSV.\n",
    "    \n",
    "    For each state:\n",
    "      - Trains an online model using columns starting with \"Is_online_\"\n",
    "      - Trains an assert model using columns starting with \"Is_HH_Have_\"\n",
    "      - Predicts on the training set and prints the correlation between predictions and the target.\n",
    "      \n",
    "    The trained models (with their corresponding polynomial transformers) are stored in a dictionary\n",
    "    and saved to disk.\n",
    "    \n",
    "    Returns:\n",
    "      trained_models: a dictionary where each key is a state and its value is:\n",
    "         {\n",
    "            'online': (poly_online, linreg_online),\n",
    "            'assert': (poly_assert, linreg_assert)\n",
    "         }\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train = pd.read_csv(train_csv)\n",
    "    \n",
    "    # Identify columns starting with \"Is_online_\" and \"Is_HH_Have_\"\n",
    "    online_cols = [col for col in train.columns if col.startswith('Is_online_')]\n",
    "    assert_cols = [col for col in train.columns if col.startswith('Is_HH_Have_')]\n",
    "    \n",
    "    # Fill missing values in these columns\n",
    "    train[online_cols] = train[online_cols].fillna(0)\n",
    "    train[assert_cols] = train[assert_cols].fillna(0)\n",
    "    \n",
    "    # Define the target variable (adjust if needed, e.g., TotalExpense/HHsize)\n",
    "    train['Target'] = train['TotalExpense']\n",
    "    \n",
    "    # Dictionary to store trained models for each state\n",
    "    trained_models = {}\n",
    "    \n",
    "    # Containers for overall predictions and targets (for overall correlation)\n",
    "    overall_preds_online = []\n",
    "    overall_targets_online = []\n",
    "    overall_preds_assert = []\n",
    "    overall_targets_assert = []\n",
    "    \n",
    "    states = sorted(train['State'].unique())\n",
    "    print(\"Training for States:\", states)\n",
    "    \n",
    "    for state in states:\n",
    "        print(f\"\\nProcessing State: {state}\")\n",
    "        state_data = train[train['State'] == state].copy()\n",
    "        \n",
    "        if state_data.shape[0] < 2:\n",
    "            print(f\"State {state} skipped due to insufficient data.\")\n",
    "            continue\n",
    "        \n",
    "        y = state_data['Target']\n",
    "        \n",
    "        # --- Online Model ---\n",
    "        X_online = state_data[online_cols]\n",
    "        poly_online = PolynomialFeatures(degree=2, include_bias=True)\n",
    "        X_online_poly = poly_online.fit_transform(X_online)\n",
    "        linreg_online = LinearRegression()\n",
    "        linreg_online.fit(X_online_poly, y)\n",
    "        preds_online = linreg_online.predict(X_online_poly)\n",
    "        \n",
    "        if y.nunique() > 1:\n",
    "            corr_online = np.corrcoef(preds_online, y)[0, 1]\n",
    "        else:\n",
    "            corr_online = np.nan\n",
    "        print(f\"State {state} - Training Correlation (Online model): {corr_online:.4f}\")\n",
    "        \n",
    "        # --- Assert Model ---\n",
    "        X_assert = state_data[assert_cols]\n",
    "        poly_assert = PolynomialFeatures(degree=2, include_bias=True)\n",
    "        X_assert_poly = poly_assert.fit_transform(X_assert)\n",
    "        linreg_assert = LinearRegression()\n",
    "        linreg_assert.fit(X_assert_poly, y)\n",
    "        preds_assert = linreg_assert.predict(X_assert_poly)\n",
    "        \n",
    "        if y.nunique() > 1:\n",
    "            corr_assert = np.corrcoef(preds_assert, y)[0, 1]\n",
    "        else:\n",
    "            corr_assert = np.nan\n",
    "        print(f\"State {state} - Training Correlation (Assert model): {corr_assert:.4f}\")\n",
    "        \n",
    "        overall_preds_online.extend(preds_online)\n",
    "        overall_targets_online.extend(y)\n",
    "        overall_preds_assert.extend(preds_assert)\n",
    "        overall_targets_assert.extend(y)\n",
    "        \n",
    "        # Save the trained models for this state\n",
    "        trained_models[state] = {\n",
    "            'online': (poly_online, linreg_online),\n",
    "            'assert': (poly_assert, linreg_assert)\n",
    "        }\n",
    "    \n",
    "    # Compute and print overall training correlations\n",
    "    overall_corr_online = np.corrcoef(overall_preds_online, overall_targets_online)[0, 1] if np.unique(overall_targets_online).size > 1 else np.nan\n",
    "    overall_corr_assert = np.corrcoef(overall_preds_assert, overall_targets_assert)[0, 1] if np.unique(overall_targets_assert).size > 1 else np.nan\n",
    "    \n",
    "    print(\"\\nCombined Training Correlations:\")\n",
    "    print(f\"Overall Online model correlation: {overall_corr_online:.4f}\")\n",
    "    print(f\"Overall Assert model correlation: {overall_corr_assert:.4f}\")\n",
    "    \n",
    "    # Save the trained models to disk\n",
    "    with open(save_model_path, \"wb\") as f:\n",
    "        pickle.dump(trained_models, f)\n",
    "    print(f\"\\nTrained models saved to {save_model_path}\")\n",
    "    \n",
    "    return trained_models\n",
    "\n",
    "def load_models(model_path=\"trained_models.pkl\"):\n",
    "    \"\"\"\n",
    "    Loads the trained models from disk.\n",
    "    \"\"\"\n",
    "    if os.path.exists(model_path):\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            trained_models = pickle.load(f)\n",
    "        print(f\"Models loaded from {model_path}\")\n",
    "        return trained_models\n",
    "    else:\n",
    "        print(f\"Model file {model_path} not found.\")\n",
    "        return None\n",
    "\n",
    "def test_models(test_csv, trained_models):\n",
    "    \"\"\"\n",
    "    Uses the trained models to generate predictions on the test CSV.\n",
    "    \n",
    "    For each state, the function:\n",
    "      - Uses the corresponding online model to compute the 'online_constant'.\n",
    "      - Uses the corresponding assert model to compute the 'having_constant'.\n",
    "      - Prints the test correlation between the predictions and the target (if available).\n",
    "    \n",
    "    Returns:\n",
    "      A DataFrame containing HH_ID, online_constant, and having_constant.\n",
    "    \"\"\"\n",
    "    test = pd.read_csv(test_csv)\n",
    "    \n",
    "    # Identify relevant columns in test data\n",
    "    online_cols = [col for col in test.columns if col.startswith('Is_online_')]\n",
    "    assert_cols = [col for col in test.columns if col.startswith('Is_HH_Have_')]\n",
    "    \n",
    "    test[online_cols] = test[online_cols].fillna(0)\n",
    "    test[assert_cols] = test[assert_cols].fillna(0)\n",
    "    \n",
    "    # Define the target variable if available (for correlation evaluation)\n",
    "    if 'TotalExpense' in test.columns:\n",
    "        test['Target'] = test['TotalExpense']\n",
    "    else:\n",
    "        test['Target'] = np.nan\n",
    "    \n",
    "    # Prepare a DataFrame for the results\n",
    "    results = test[['HH_ID', 'State']].copy()\n",
    "    results['online_constant'] = np.nan\n",
    "    results['having_constant'] = np.nan\n",
    "    \n",
    "    overall_preds_online = []\n",
    "    overall_targets_online = []\n",
    "    overall_preds_assert = []\n",
    "    overall_targets_assert = []\n",
    "    \n",
    "    states = sorted(test['State'].unique())\n",
    "    print(\"\\nTesting for States:\", states)\n",
    "    \n",
    "    for state in states:\n",
    "        print(f\"\\nProcessing State: {state}\")\n",
    "        state_data = test[test['State'] == state].copy()\n",
    "        if state not in trained_models:\n",
    "            print(f\"No trained model for State {state}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Get models for the state\n",
    "        poly_online, linreg_online = trained_models[state]['online']\n",
    "        poly_assert, linreg_assert = trained_models[state]['assert']\n",
    "        \n",
    "        # Predict online feature\n",
    "        X_online = state_data[online_cols]\n",
    "        X_online_poly = poly_online.transform(X_online)\n",
    "        preds_online = linreg_online.predict(X_online_poly)\n",
    "        \n",
    "        # Predict assert feature\n",
    "        X_assert = state_data[assert_cols]\n",
    "        X_assert_poly = poly_assert.transform(X_assert)\n",
    "        preds_assert = linreg_assert.predict(X_assert_poly)\n",
    "        \n",
    "        results.loc[results['State'] == state, 'online_constant'] = preds_online\n",
    "        results.loc[results['State'] == state, 'having_constant'] = preds_assert\n",
    "        \n",
    "        # Evaluate correlations if target variation exists\n",
    "        if state_data['Target'].nunique() > 1:\n",
    "            corr_online = np.corrcoef(preds_online, state_data['Target'])[0, 1]\n",
    "            corr_assert = np.corrcoef(preds_assert, state_data['Target'])[0, 1]\n",
    "            print(f\"State {state} - Test Correlation (Online model): {corr_online:.4f}\")\n",
    "            print(f\"State {state} - Test Correlation (Assert model): {corr_assert:.4f}\")\n",
    "        else:\n",
    "            print(f\"State {state} - Insufficient target variation for correlation evaluation.\")\n",
    "        \n",
    "        overall_preds_online.extend(preds_online)\n",
    "        overall_targets_online.extend(state_data['Target'])\n",
    "        overall_preds_assert.extend(preds_assert)\n",
    "        overall_targets_assert.extend(state_data['Target'])\n",
    "    \n",
    "    overall_corr_online = np.corrcoef(overall_preds_online, overall_targets_online)[0, 1] if np.unique(overall_targets_online).size > 1 else np.nan\n",
    "    overall_corr_assert = np.corrcoef(overall_preds_assert, overall_targets_assert)[0, 1] if np.unique(overall_targets_assert).size > 1 else np.nan\n",
    "    \n",
    "    print(\"\\nCombined Testing Correlations:\")\n",
    "    print(f\"Overall Online model correlation: {overall_corr_online:.4f}\")\n",
    "    print(f\"Overall Assert model correlation: {overall_corr_assert:.4f}\")\n",
    "    \n",
    "    # Optionally drop the State column\n",
    "    results = results.drop(columns=['State'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ----------------------- Example Usage -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths for your training and testing CSV files\n",
    "    train_csv_path = train_data_hh_path\n",
    "    test_csv_path = test_data_hh_path\n",
    "    model_save_path = 'trained_models.pkl'\n",
    "    \n",
    "    # Train models and save them\n",
    "    trained_models = load_models(model_path = model_save_path)\n",
    "    \n",
    " \n",
    "    test_results = test_models(test_csv_path, trained_models)\n",
    "    \n",
    "    # Optionally, save the test results to CSV\n",
    "    test_results.to_csv(\"test_features.csv\", index=False)\n",
    "    \n",
    "    print(\"\\nTest features head:\")\n",
    "    print(test_results.head())\n",
    "processed_df = pd.merge(processed_df,test_models(test_data_hh_path,trained_models),on='HH_ID',how='left')\n",
    "processed_df_t = pd.merge(processed_df_t,test_models(train_data_hh_path,trained_models),on='HH_ID',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal_level_constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from expense_model.pkl\n",
      "                                       HH_ID  Personal_level_constant\n",
      "0        HCES2022699591212130623068221111306             13983.501952\n",
      "1        HCES2022325492191931132028219201301              8827.609071\n",
      "2        HCES2022331532151510322037115101308             33283.613853\n",
      "3        HCES2022622821121210923037212102315             18623.648783\n",
      "4       HCES20223918022929318420110229101301             20913.300986\n",
      "...                                      ...                      ...\n",
      "209391  HCES20223939722929402120210129211301             13983.501952\n",
      "209392   HCES2022394042323220712044132131303             29084.981092\n",
      "209393   HCES2022651761050511123016205111303             23942.888184\n",
      "209394   HCES2022355062010131042026101201211             18147.789920\n",
      "209395   HCES2022350372080820722025108211311             18147.789920\n",
      "\n",
      "[209396 rows x 2 columns]\n",
      "                                      HH_ID  Personal_level_constant\n",
      "0       HCES2022619881191951823044219131316             13264.009191\n",
      "1       HCES2022617721191931723197219202205             21338.711041\n",
      "2       HCES2022632771101011022015110131311             15998.549434\n",
      "3       HCES2022357832080822112037108101306             21169.877528\n",
      "4      HCES20226869012727230232010227422206             14963.032121\n",
      "...                                     ...                      ...\n",
      "52345   HCES2022625161101010223331210124304             20655.643468\n",
      "52346   HCES2022677831343410223012133233316             22098.047274\n",
      "52347   HCES2022666521080832623162208123306             17466.578870\n",
      "52348   HCES2022398492323220712078232131305             18277.384759\n",
      "52349   HCES2022669761090935323106209222101             21169.609826\n",
      "\n",
      "[52350 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "class HouseholdExpenseModel:\n",
    "    def __init__(self):\n",
    "        # Define base columns for food and non-food features\n",
    "        self.food_columns = [\n",
    "            'meals_per_day', 'meals_school', 'meals_employer', \n",
    "            'meals_others', 'meals_paid', 'meals_home'\n",
    "        ]\n",
    "        self.non_food_columns = ['days_away']\n",
    "        # Pipeline for training a CatBoost regressor with imputation.\n",
    "        self.model = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('catboost', CatBoostRegressor(random_state=42, verbose=0))\n",
    "        ])\n",
    "        self.combined_features = None  # Will be defined during training\n",
    "\n",
    "    def preprocess(self, df_person, df_household):\n",
    "        \"\"\"Aggregates person-level features and merges them with household data.\"\"\"\n",
    "        # Rename columns for clarity\n",
    "        df_person = df_person.rename(columns={\n",
    "            \"HH_ID\": \"HH_ID\",\n",
    "            \"No. of days stayed away from home during last 30 days\": \"days_away\",\n",
    "            \"No. of meals usually taken in a day\": \"meals_per_day\",\n",
    "            \"No. of meals taken during last 30 days from school, balwadi etc.\": \"meals_school\",\n",
    "            \"No. of meals taken during last 30 days from employer as perquisites or part of wage\": \"meals_employer\",\n",
    "            \"No. of meals taken during last 30 days  others\": \"meals_others\",\n",
    "            \"No. of meals taken during last 30 days on payment\": \"meals_paid\",\n",
    "            \"No. of meals taken during last 30 days at home\": \"meals_home\"\n",
    "        })\n",
    "\n",
    "        # Aggregate food-related features: compute both sum and mean\n",
    "        agg_food = df_person.groupby('HH_ID')[self.food_columns].agg(['sum', 'mean'])\n",
    "        agg_food.columns = ['_'.join(col) for col in agg_food.columns]  # Flatten MultiIndex\n",
    "        agg_food.reset_index(inplace=True)\n",
    "\n",
    "        # Aggregate non-food features (days_away): compute sum and mean\n",
    "        agg_non_food = df_person.groupby('HH_ID')[self.non_food_columns].agg(['sum', 'mean'])\n",
    "        agg_non_food.columns = ['_'.join(col) for col in agg_non_food.columns]\n",
    "        agg_non_food.reset_index(inplace=True)\n",
    "\n",
    "        # Merge the aggregated data with the household-level data\n",
    "        df_merged = pd.merge(df_household, agg_food, on='HH_ID', how='left')\n",
    "        df_merged = pd.merge(df_merged, agg_non_food, on='HH_ID', how='left')\n",
    "\n",
    "        return df_merged\n",
    "\n",
    "    def fit(self, df_person_train, df_household_train):\n",
    "        \"\"\"Fits the model on the training dataset.\"\"\"\n",
    "        df_merged = self.preprocess(df_person_train, df_household_train)\n",
    "        # Define the combined feature list: all columns starting with 'meals' or 'days_away'\n",
    "        self.combined_features = [col for col in df_merged.columns if col.startswith('meals') or col.startswith('days_away')]\n",
    "        # Features and target: using TotalExpense as the target variable\n",
    "        X_train = df_merged[self.combined_features]\n",
    "        y_train = df_merged['TotalExpense']\n",
    "        # Train the pipeline model\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, df_person, df_household):\n",
    "        \"\"\"Generates predictions for the provided dataset.\"\"\"\n",
    "        df_merged = self.preprocess(df_person, df_household)\n",
    "        X = df_merged[self.combined_features]\n",
    "        df_merged['Personal_level_constant'] = self.model.predict(X)\n",
    "        return df_merged[['HH_ID', 'Personal_level_constant']]\n",
    "\n",
    "    def evaluate(self, df_person, df_household):\n",
    "        \"\"\"Evaluates the model by computing the correlation between predicted expense and actual TotalExpense.\"\"\"\n",
    "        df_merged = self.preprocess(df_person, df_household)\n",
    "        X = df_merged[self.combined_features]\n",
    "        df_merged['Personal_level_constant'] = self.model.predict(X)\n",
    "        # Compute Pearson correlation between predicted expense and actual TotalExpense\n",
    "        correlation = np.corrcoef(df_merged['Personal_level_constant'], df_merged['TotalExpense'])[0, 1]\n",
    "        return correlation, df_merged\n",
    "\n",
    "    def save_model(self, filename=\"expense_model.pkl\"):\n",
    "        \"\"\"Saves the complete model pipeline to a pickle file.\"\"\"\n",
    "        joblib.dump(self, filename)\n",
    "        print(f\"Model saved as {filename}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(filename=\"expense_model.pkl\"):\n",
    "        \"\"\"Loads the model pipeline from a pickle file.\"\"\"\n",
    "        model = joblib.load(filename)\n",
    "        print(f\"Model loaded from {filename}\")\n",
    "        return model\n",
    "\n",
    "\n",
    "df_person_train = pd.read_csv(train_data_per_path)\n",
    "df_household_train = pd.read_csv(train_data_hh_path)\n",
    "\n",
    "df_person_test = pd.read_csv(test_data_per_path)\n",
    "df_household_test = pd.read_csv(test_data_hh_path)\n",
    "\n",
    "\n",
    "expense_model = HouseholdExpenseModel.load_model('expense_model.pkl')\n",
    "print(expense_model.predict(df_person_train, df_household_train))\n",
    "print(expense_model.predict(df_person_test, df_household_test))\n",
    "\n",
    "processed_df = pd.merge(processed_df,expense_model.predict(df_person_test, df_household_test),on='HH_ID',how='left')\n",
    "processed_df_t = pd.merge(processed_df_t,expense_model.predict(df_person_train, df_household_train),on='HH_ID',how='left')\n",
    "\n",
    "cols = processed_df.columns.tolist()\n",
    "i1 = cols.index(\"having_constant\")\n",
    "i2 = cols.index(\"online_constant\")\n",
    "cols[i1], cols[i2] = cols[i2], cols[i1]\n",
    "test_processed = processed_df[cols]\n",
    "\n",
    "cols = processed_df_t.columns.tolist()\n",
    "i1 = cols.index(\"having_constant\")\n",
    "i2 = cols.index(\"online_constant\")\n",
    "cols[i1], cols[i2] = cols[i2], cols[i1]\n",
    "train_processed = processed_df[cols]\n",
    "test_processed.to_csv('test_processed.csv',index=False)\n",
    "train_processed.to_csv('train_processed.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
